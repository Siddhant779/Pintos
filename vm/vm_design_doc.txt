                     +---------------------------+
                     |         EE 461S           |
                     | PROJECT 3: VIRTUAL MEMORY |
                     |      DESIGN DOCUMENT      |
                     +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Siyuan (Tim) Chen timchenut567@utexas.edu
Saumya Jain saumyajain@utexas.edu
David Li davidli216@utexas.edu
Siddhant Pandit panditsiddhant.sp@utexas.edu

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                   SUPPLEMENTAL PAGE TABLE MANAGEMENT
                   ==================================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Frame Table **
Swap Table **
Supplemental Page Table **


---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for accessing the data
>> stored in the SPT about a given page.

To access the data stored in the SPT about a given page, the code involves performing a 
hash table lookup based on the virtual address of the page. This lookup gives a pointer 
to the corresponding SPTE. Once the entry is obtained, the code can access various fields 
in the entry to gather information about the page. 
For example, the code might check if the page is currently in memory or swapped out, 
and if it is on disk, the code would also contain information about the location of 
the page.
Specifically in our code: 
   Initialization:
   The `SPT_init` function initializes a new SPT. It allocates memory for the SPT structure, 
   initializes a lock for synchronization, and initializes a hash table (`page_entries`) to 
   store page entries. Each entry in this hash table corresponds to a virtual page in the 
   process's address space.

   Hash Functions: 
   - `SPT_hash_func`: This function computes a hash value for a given page entry based on its 
      virtual address (`upage`). It is used as the hash function when inserting and searching for 
      elements in the hash table.
   - `SPT_less_func`: This function defines the order of elements in the hash table. It compares 
      two page entries based on their virtual addresses.
   
   Lookup Functions:
   The `lookup_page` function takes a virtual address (`upage`) as input and searches the SPT for the 
   corresponding page entry. It computes the hash value for the given virtual address and uses `hash_find` 
   to find the corresponding element in the `page_entries` hash table. If the element is found, it returns
   a pointer to the corresponding `struct SPTE` (Supplemental Page Table Entry) containing information about 
   the page.

   Page Installation: 
   The `SPTE_install_file` function is responsible for creating and populating a new page entry in the SPT.
   It takes parameters such as the file pointer (`file`), file offset (`ofs`), virtual address (`upage`), 
   read and zero bytes, write permission (`writable`), page directory pointer (`pagedir`), and the current 
   thread (`t`). It allocates memory for a new `struct SPTE`, populates its fields with the provided 
   information, and inserts it into the SPT using `hash_insert`. If the insertion is successful 
   (for example, the page entry does not already exist in the SPT), the function returns `true`; otherwise, 
   it returns `false`.

   The `SPTE_install_file` function initializes a new page entry for a specific virtual page and associates 
   it with a file. The file pointer, with the file offset, allows the operating system to know which part of 
   the file corresponds to the given page. When this page needs to be loaded into memory, the file data can be 
   read from the specified offset. 

   **Include something about page load??**

---- SYNCHRONIZATION ----

>> A3: When two user processes both need a new frame at the same time,
>> how are races avoided?

The frame table is protected by a lock so that only one process can access and modify it at a time. 

---- RATIONALE ----

>> A4: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?

We chose to implement our own structs for the supplemental page table entries (SPTE) and frame table entries (FTE) 
because we wanted more control over what information was stored for virtual-to-physical memory mappings. The SPTE 
keeps track of a virtual page address (upage) as well as the physical memory frame that it is mapped to (kpage).
The FTE keeps track of the SPTE that is currently mapped to it which in turns allows access to the upage and kpage.
The supplemental page table itself is a hashtable that uses the virtual page address (upage) as a key that maps to
a SPTE through a hash function. We chose to use a hash table as it allows easy and quick access of individual
SPTEs from just the upage itself, which is very convenient whenever processing virtual memory and loading pages.
For the frames, we used both a bitmap and also an array. First is a bitmap of length 267 (one for each frame) 
that is either a '0' if the frame is unused, or a '1' if the frame is occupied. The bitmap allows us to easily 
find an open frame to map a page to, which is used in our get_frames function. We also sed a basic array of FTEs 
for the frame table itself. We chose to use an array because arrays are easy to traverse, which is useful during 
the eviction process and also because array indexing matches that of bitmap indexing, which makes arrays easy to 
use alongside bitmaps.

                        PAGING TO AND FROM DISK
                        =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

-> clock algorithm? 

>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?

>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.


---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)
Our VM synchronization design incorporates locks at various layers to make sure our data structures 
are safe and prevent deadlock scenarios.
- At the frame table layer, a single lock is used, carefully avoiding circular dependencies by ensuring
that the only lock acquired while it is held is the supplemental page table entry lock for the specific 
entry of concern. This sequential acquisition reduces the risk of deadlock.
- The swap table bitmap, tracking used and free bits, operates in a lock-free manner to eliminate the 
possibility of circular dependencies and deadlock.
- Each process maintains a lock for its hash table of supplemental page table entries, used during 
lookups and modifications. To prevent potential deadlock, we ensure that the supplemental page table 
entry lock is acquired before releasing the hash table lock during a lookup, removing any code 
that might create a cycle.
- Global file system lock usage in file system operations is encapsulated within dedicated functions, 
preventing concurrent holding of different locks by multiple processes and avoiding potential deadlock 
scenarios.
The specific conditions for deadlock are mutual excluision, no preemption, hold and wait, and circular wait. 
We addressed ways to prevent each of these by guarding using locks, disabling preemption to prevent the interruption 
of a threat holding a lock and ensuring that the thread completes its critical section before other threads can execute,
releasing any locks a thread has before attempting to acquire new ones, and establishing a clear order for acquiring locks. 


>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?
There is a lock on the SPTE, which needs to be acquired in order to access a prtciular page or evict it. 
While evicting, we get the lock that is on the SPTE corresponding to whichever page is being evicted. Then the 
page is cleared and process Q tries to access the evicted page but it is unsuccessful and triggers a page fault. 
We prevent Q from accessing or modifying the page during eviction because Q looks up the SPTE but it will be unable to 
acquire the lock. This avoids race conditions when P evicts the frame and Q faulting back in. 


>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?
To ensure a second process cannot interfere, we implemented pinning. If a process loads a frame, it is pinned
and these pinned frames cannot be a part of the clock algorithm that is implemented. This means that those frames
cannot be assigned to another process like Q in this situation until they are unpinned which will happen after 
the loading in P is complete. 

>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?

During the eviction process, non-dirty pages will be simply booted from memory to make space. Whenever something tries to access a paged out
page, the system will simply page fault and then lazy load the missing page back into physical memory. However, this can be an issue during some 
system calls such as the read and write syscalls as they involve buffers that should be preserved and not evicted for the duration of the syscall.
We therefore have a system of page pinning wherein the pages corresponding to the buffers used in these syscalls are marked as "pinned" when
the syscall begins and then unmarked when the syscall ends. During the eviction process, frames with pages marked as "pinned" will not be
evicted, ensuring that the pages are maintained during the syscall and cannot be paged out or evicted from physical memory. If an invalid virtual 
address is accessed, the program will page fault and depending on circumstances can grow the stack, lazy load into memory, or exit the process.

---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

Our implementation is somewhere in the middle of the two extremes listed above, closer to the single lock side.
We mostly user three types of locks for synchronization, SPT locks, a single frame lock, and a swap lock.
The frame and swap locks are shared by all threads in the system and only one thread can hold it at once, limiting
the parallelism. However, the SPT locks are implemented on a per-thread basis, allowing for more parallelism. 
We chose to implement it this way because the frame table and swap space resources are shared between all threads,
so it makes sense to lock it across all threads. Meanwhile, the SPT resources are not shared across threads and 
each thread has its own SPT, so it is more efficient to lock it within the thread. If there was a single SPT lock,
each thread would need to wait to edit its own SPT.

                           SURVEY QUESTIONS
                           ================

Answering these questions is optional, but it will help us improve the
course in future semesters.  Feel free to tell us anything you
want -- these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the semester.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future semesters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future semesters or the remaining projects?

>> Any other comments?
